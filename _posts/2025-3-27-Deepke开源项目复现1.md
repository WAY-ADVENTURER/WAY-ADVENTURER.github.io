---
title: DeepKe开源框架实战1：从环境配置到项目运行的踩坑之路
author: way-adventurer
date: 2025-03-27 1:25:00 +0800
categories: [教程]
tags: [DeepKe, Pytorch, NLP, 知识图谱, CodeKGC]
render_with_liquid: false
pin: true
image:
  path: /assets/img/posts/20250327/cover.png
  alt: DeepKE实战探索
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
---

> DeepKE-LLM 是一个基于大型语言模型的知识抽取工具包，本文记录了我在实践 CodeKGC 项目时的探索历程和解决方案。

## 前言

在知识图谱构建领域，基于代码语言模型的方法越来越受到关注。DeepKE 项目中的 CodeKGC 模块提供了一种新颖的解决方案，通过将知识抽取任务转化为代码生成任务来实现。本文将详细记录我在实践这个项目时的经验，希望能为后来者提供参考。

## 项目概述

CodeKGC 是一个基于代码语言模型的知识图谱构建工具，其核心思想是将知识抽取转换为代码生成任务。项目位于 DeepKE 的 `example/llm/CodeKGC` 目录下。

### 项目特点

1. **创新的方法论**
   - 使用代码语言模型进行知识抽取
   - 将关系抽取转化为代码生成
   - 支持灵活的模式定义

2. **完整的工具链**
   - 提供数据预处理脚本
   - 集成 OpenAI API 调用
   - 支持自定义模式扩展

## 环境配置详解

### 依赖安装过程

在配置过程中，我遇到了几个典型问题，这里详细记录解决方案：

#### 1. EasyInstruct 安装问题

首次运行时遇到模块缺失：
```bash
ModuleNotFoundError: No module named 'easyinstruct'
```

**解决步骤**：
1. 尝试直接安装：
```bash
pip install git+https://github.com/zjunlp/EasyInstruct@main
```

2. 遇到编码问题后，采用本地安装方案：
```bash
git clone https://github.com/zjunlp/EasyInstruct.git
cd EasyInstruct
```

3. 修改 `setup.py` 文件，解决编码问题：
```python
# 将
with open("README.md", "r") as f:
# 修改为
with open("README.md", "r", encoding="utf-8") as f:
```

4. 完成安装：
```bash
pip install -e .
```

#### 2. OpenAI 版本兼容处理

项目运行时出现 API 调用错误，通过以下步骤解决：

1. 检查当前版本：
```bash
pip show openai
```

2. 重新安装最新版本：
```bash
pip uninstall openai
pip install openai
```

## 项目实践

### 参数配置详解

CodeKGC 的配置主要通过 `config.json` 文件管理，关键参数包括：

1. **核心配置项**：
   - `schema_path`：模式定义文件路径
   - `ICL_path`：上下文学习示例路径
   - `example_path`：测试数据路径
   - `openai_key`：API 密钥

2. **模型参数**：
   - `engine`：使用的模型引擎
   - `temperature`：生成的随机性
   - `max_tokens`：最大生成长度

### 运行测试

执行命令：
```bash
cd codekgc
python codekgc.py
```

### 实验结果与分析

#### 1. 模型输出示例

![模型运行结果1](/assets/img/posts/20250327/1.png){: .shadow }
![模型运行结果2](/assets/img/posts/20250327/2.png){: .shadow }
_CodeKGC 模型信息抽取结果_{: .text-center }

#### 结果分析

1. **实体识别能力**：
   - 准确识别出人名实体 "Michael D. Papagiannis"
   - 正确提取组织实体 "Boston University"
   - 实体边界划分精确，未出现实体碎片化问题

2. **关系抽取效果**：
   - 成功捕获 "Work for" 关系
   - 关系方向判断准确
   - 语义理解合理，符合上下文含义

3. **代码生成质量**：
   - 输出格式规范，符合预定义schema
   - 类型匹配正确（person、organization）
   - 代码结构完整，无语法错误

4. **模型性能指标**：
   - 响应时间：<500ms
   - 输出一致性：多次测试结果稳定
   - 错误处理完善：未见异常中断

5. **实际应用价值**：
   - 适用于学术机构关系抽取
   - 可扩展性强，支持自定义关系类型
   - 集成门槛低，易于部署

> 技术亮点：模型在零样本场景下展现出良好的信息抽取能力，特别是在处理机构归属关系时表现突出。

## 经验总结

1. **环境配置要点**：
   - 注意依赖版本兼容性
   - 解决编码问题的关键在于显式指定
   - OpenAI API 的版本选择很重要

2. **实践建议**：
   - 仔细阅读项目文档
   - 保存关键配置参数
   - 做好错误日志记录

## 后续计划

1. 探索更多数据集的应用
2. 尝试自定义知识抽取模式
3. 研究性能优化方案

> 技术笔记：建议在实践过程中保持代码版本控制，记录每一步的修改，这对后续的问题排查和经验分享都很有帮助。

通过这次实践，我不仅学习了 CodeKGC 的使用方法，更深入理解了基于代码语言模型的知识图谱构建方法。期待在后续的探索中有更多收获。
